{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0142506d",
   "metadata": {},
   "source": [
    "# PROJECT GOA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92133e4d",
   "metadata": {},
   "source": [
    "The Requirement of a Business Problem is to develop a predictive model to Analyse and to classify the grades of student pursued in academics using Classification Analysis with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries¶\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader Function to Load Dataframe¶\n",
    "path =\"https://raw.githubusercontent.com/DheerajKumar97/Student-Perfomance-Analytics/master/StudentsPerformance.csv\"\n",
    "class DataFrame_Loader():\n",
    "    data = path\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Loadind DataFrame\")\n",
    "        \n",
    "    def read_csv(self,data):\n",
    "        self.df = pd.read_csv(data)\n",
    "        \n",
    "    def load_csv(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb58a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20989898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.load_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'math score':'math_score','reading score':'reading_score','writing score':'writing_score'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe8bf9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d892a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrame_Information():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Attribute Information object created\")\n",
    "        \n",
    "    def Attribute_information(self,df):\n",
    "    \n",
    "        data_info = pd.DataFrame(\n",
    "                                columns=['No of observation',\n",
    "                                        'No of Variables',\n",
    "                                        'No of Numerical Variables',\n",
    "                                        'No of Factor Variables',\n",
    "                                        'No of Categorical Variables',\n",
    "                                        'No of Logical Variables',\n",
    "                                        'No of Date Variables',\n",
    "                                        'No of zero variance variables'])\n",
    "\n",
    "\n",
    "        data_info.loc[0,'No of observation'] = df.shape[0]\n",
    "        data_info.loc[0,'No of Variables'] = df.shape[1]\n",
    "        data_info.loc[0,'No of Numerical Variables'] = df._get_numeric_data().shape[1]\n",
    "        data_info.loc[0,'No of Factor Variables'] = df.select_dtypes(include='category').shape[1]\n",
    "        data_info.loc[0,'No of Logical Variables'] = df.select_dtypes(include='bool').shape[1]\n",
    "        data_info.loc[0,'No of Categorical Variables'] = df.select_dtypes(include='object').shape[1]\n",
    "        data_info.loc[0,'No of Date Variables'] = df.select_dtypes(include='datetime64').shape[1]\n",
    "        data_info.loc[0,'No of zero variance variables'] = df.loc[:,df.apply(pd.Series.nunique)==1].shape[1]\n",
    "\n",
    "        data_info =data_info.transpose()\n",
    "        data_info.columns=['value']\n",
    "        data_info['value'] = data_info['value'].astype(int)\n",
    "\n",
    "\n",
    "        return data_info\n",
    "\n",
    "    def __get_missing_values(self,data):\n",
    "        \n",
    "        #Getting sum of missing values for each feature\n",
    "        missing_values = data.isnull().sum()\n",
    "        #Feature missing values are sorted from few to many\n",
    "        missing_values.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        #Returning missing values\n",
    "        return missing_values\n",
    "\n",
    "    def Generate_Schema(self,data):\n",
    "        \n",
    "        feature_dtypes=data.dtypes\n",
    "        self.missing_values=self.__get_missing_values(data)\n",
    "\n",
    "        print(\"=\" * 110)\n",
    "\n",
    "        print(\"{:16} {:16} {:20} {:16}\".format(\"Feature Name\".upper(),\n",
    "                                            \"Data Type\".upper(),\n",
    "                                            \"# of Missing Values\".upper(),\n",
    "                                            \"Samples\".upper()))\n",
    "        for feature_name, dtype, missing_value in zip(self.missing_values.index.values,\n",
    "                                                      feature_dtypes[self.missing_values.index.values],\n",
    "                                                      self.missing_values.values):\n",
    "            print(\"{:18} {:19} {:19} \".format(feature_name, str(dtype), str(missing_value)), end=\"\")\n",
    "            for v in data[feature_name].values[:5]:\n",
    "                print(v, end=\",\")\n",
    "            print()\n",
    "\n",
    "        print(\"=\"*110)\n",
    "        \n",
    "    def Agg_Tabulation(self,data):\n",
    "        \n",
    "        print(\"=\" * 110)\n",
    "        print(\"Aggregation of Table\")\n",
    "        print(\"=\" * 110)\n",
    "        table = pd.DataFrame(data.dtypes,columns=['dtypes'])\n",
    "        table1 =pd.DataFrame(data.columns,columns=['Names'])\n",
    "        table = table.reset_index()\n",
    "        table= table.rename(columns={'index':'Name'})\n",
    "        table['No of Missing'] = data.isnull().sum().values    \n",
    "        table['No of Uniques'] = data.nunique().values\n",
    "        table['Percent of Missing'] = ((data.isnull().sum().values)/ (data.shape[0])) *100\n",
    "        table['First Observation'] = data.loc[0].values\n",
    "        table['Second Observation'] = data.loc[1].values\n",
    "        table['Third Observation'] = data.loc[2].values\n",
    "        for name in table['Name'].value_counts().index:\n",
    "            table.loc[table['Name'] == name, 'Entropy'] = round(stats.entropy(data[name].value_counts(normalize=True), base=2),2)\n",
    "        return table\n",
    "    \n",
    "        print(\"=\" * 110)\n",
    "        \n",
    "    def __IQR(self,x):\n",
    "        return x.quantile(q=0.75) - x.quantile(q=0.25)\n",
    "\n",
    "    def __Outlier_Count(self,x):\n",
    "        upper_out = x.quantile(q=0.75) + 1.5 * self.__IQR(x)\n",
    "        lower_out = x.quantile(q=0.25) - 1.5 * self.__IQR(x)\n",
    "        return len(x[x > upper_out]) + len(x[x < lower_out])\n",
    "\n",
    "    def Numeric_Count_Summary(self,df):\n",
    "        df_num = df._get_numeric_data()\n",
    "        data_info_num = pd.DataFrame()\n",
    "        i=0\n",
    "        for c in  df_num.columns:\n",
    "            data_info_num.loc[c,'Negative values count']= df_num[df_num[c]<0].shape[0]\n",
    "            data_info_num.loc[c,'Positive values count']= df_num[df_num[c]>0].shape[0]\n",
    "            data_info_num.loc[c,'Zero count']= df_num[df_num[c]==0].shape[0]\n",
    "            data_info_num.loc[c,'Unique count']= len(df_num[c].unique())\n",
    "            data_info_num.loc[c,'Negative Infinity count']= df_num[df_num[c]== -np.inf].shape[0]\n",
    "            data_info_num.loc[c,'Positive Infinity count']= df_num[df_num[c]== np.inf].shape[0]\n",
    "            data_info_num.loc[c,'Missing Percentage']= df_num[df_num[c].isnull()].shape[0]/ df_num.shape[0]\n",
    "            data_info_num.loc[c,'Count of outliers']= self.__Outlier_Count(df_num[c])\n",
    "            i = i+1\n",
    "        return data_info_num\n",
    "    \n",
    "    def Statistical_Summary(self,df):\n",
    "    \n",
    "        df_num = df._get_numeric_data()\n",
    "\n",
    "        data_stat_num = pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            data_stat_num = pd.concat([df_num.describe().transpose(),\n",
    "                                       pd.DataFrame(df_num.quantile(q=0.10)),\n",
    "                                       pd.DataFrame(df_num.quantile(q=0.90)),\n",
    "                                       pd.DataFrame(df_num.quantile(q=0.95))],axis=1)\n",
    "            data_stat_num.columns = ['count','mean','std','min','25%','50%','75%','max','10%','90%','95%']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return data_stat_num\n",
    "    \n",
    "    def group_by_Num_variables(self,df,x,y):\n",
    "        d=df.groupby([x])[y].describe()\n",
    "        data_stat_num = pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "                data_stat_num = pd.concat([d,\n",
    "                                           pd.DataFrame(df_num.quantile(q=0.10)),\n",
    "                                           pd.DataFrame(df_num.quantile(q=0.90)),\n",
    "                                           pd.DataFrame(df_num.quantile(q=0.95))],axis=1)\n",
    "                data_stat_num.columns = ['count','mean','std','min','25%','50%','75%','max','10%','90%','95%']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return data_stat_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f968cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info = DataFrame_Information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info.Attribute_information(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39791e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info.Generate_Schema(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78117aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info.Agg_Tabulation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e389fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info.Numeric_Count_Summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info.Statistical_Summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1beb0",
   "metadata": {},
   "source": [
    "# EDA and Preprocessing With Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "class DataFrame_Visualizer():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Visualizer object created\")\n",
    "        \n",
    "    def Bar_graph(self,df,x):\n",
    "        plt.figure(figsize=(20,7))\n",
    "        x.value_counts(normalize = True)\n",
    "        x.value_counts(dropna = False).plot.bar(color='blue')\n",
    "        plt.xlabel('variable')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def cross_tab_with_stacked_bar_chart(self,df,x,y):\n",
    "        x = pd.crosstab(x, y)\n",
    "        return x.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (4, 4))\n",
    "    \n",
    "    def count_plot_for_variables(self,df,x,y,z):\n",
    "        sns.countplot(x = x, data = df, hue = y, palette = z)\n",
    "        plt.show()\n",
    "        \n",
    "    def Calculate_Pass_Math_with_math_score(self,df):    \n",
    "        passmarks = 40\n",
    "\n",
    "        # creating a new column pass_math, this column will tell us whether the students are pass or fail\n",
    "        df['pass_math'] = np.where(df['math_score']< passmarks, 'Fail', 'Pass')\n",
    "        df['pass_math'].value_counts(dropna = False).plot.bar(color = 'black', figsize = (5, 3))\n",
    "\n",
    "        plt.title('Comparison of students passed or failed in maths')\n",
    "        plt.xlabel('status')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "\n",
    "    def Calculate_Marks_with_math_score(self,df):\n",
    "    \n",
    "        passmarks = 40\n",
    "\n",
    "        df['pass_writing'] = np.where(df['math_score']< passmarks, 'Fail', 'Pass')\n",
    "        df['pass_writing'].value_counts(dropna = False).plot.bar(color = 'green', figsize = (5, 3))\n",
    "\n",
    "        plt.title('Comparison of students passed or failed in maths')\n",
    "        plt.xlabel('status')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def Calculate_Marks_with_writing_score(self,df):\n",
    "        \n",
    "        passmarks = 40\n",
    "\n",
    "        df['pass_writing'] = np.where(df['writing_score']< passmarks, 'Fail', 'Pass')\n",
    "        df['pass_writing'].value_counts(dropna = False).plot.bar(color = 'blue', figsize = (5, 3))\n",
    "\n",
    "        plt.title('Comparison of students passed or failed in maths')\n",
    "        plt.xlabel('status')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def Calculate_total_Score_with_math_score(self,df):\n",
    "        \n",
    "        df['total_score'] = df['math_score'] + df['reading_score'] + df['writing_score']\n",
    "\n",
    "        df['total_score'].value_counts(normalize = True)\n",
    "        df['total_score'].value_counts(dropna = True).plot.bar(color = 'red', figsize = (40, 8))\n",
    "\n",
    "        plt.title('comparison of total score of all the students')\n",
    "        plt.xlabel('total score scored by the students')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "     \n",
    "    def Calculate_percentage_with_total_Score(self,df):\n",
    "\n",
    "        df['percentage'] = df['total_score']/3\n",
    "\n",
    "        for i in range(0, 1000):\n",
    "            df['percentage'][i] = ceil(df['percentage'][i])\n",
    "\n",
    "        df['percentage'].value_counts(normalize = True)\n",
    "        df['percentage'].value_counts(dropna = False).plot.bar(figsize = (16, 8), color = 'red')\n",
    "\n",
    "        plt.title('Comparison of percentage scored by all the students')\n",
    "        plt.xlabel('percentage score')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def Calculate_pass_reading_with_reading_score(self,df):    \n",
    "        \n",
    "        passmarks = 40\n",
    "        df['pass_reading'] = np.where(df['reading_score']< passmarks, 'Fail', 'Pass')\n",
    "        df['pass_reading'].value_counts(dropna = False).plot.bar(color = 'brown', figsize = (5, 3))\n",
    "\n",
    "        plt.title('Comparison of students passed or failed in maths')\n",
    "        plt.xlabel('status')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def Calculate_status_with_pass_math_and_pass_writing(self,df):\n",
    "        \n",
    "        passmarks = 40\n",
    "        df['status'] = df.apply(lambda x : 'Fail' if x['pass_math'] == 'Fail' or \n",
    "                           x['pass_reading'] == 'Fail' or x['pass_writing'] == 'Fail'\n",
    "                           else 'pass', axis = 1)\n",
    "\n",
    "        df['status'].value_counts(dropna = False).plot.bar(color = 'gray', figsize = (3, 3))\n",
    "        plt.title('overall results')\n",
    "        plt.xlabel('status')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "    def pie_chart(self):\n",
    "    \n",
    "        labels = ['Grade 0', 'Grade A', 'Grade B', 'Grade C', 'Grade D', 'Grade E']\n",
    "        sizes = [58, 156, 260, 252, 223, 51]\n",
    "        colors = ['yellow', 'gold', 'lightskyblue', 'lightcoral', 'pink', 'cyan']\n",
    "        explode = (0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001)\n",
    "\n",
    "        patches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90)\n",
    "        plt.legend(patches, labels)\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def getgrade(self,percentage, status):\n",
    "        if status == 'Fail':\n",
    "            return 'E'\n",
    "        if(percentage >= 90):\n",
    "            return 'O'\n",
    "        if(percentage >= 80):\n",
    "            return 'A'\n",
    "        if(percentage >= 70):\n",
    "            return 'B'\n",
    "        if(percentage >= 60):\n",
    "            return 'C'\n",
    "        if(percentage >= 40):\n",
    "            return 'D'\n",
    "        else :\n",
    "            return 'E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = DataFrame_Visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e463c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['lunch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c86771",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['race/ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['math_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['reading_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ad85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Bar_graph(df,df['writing_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['gender'],df['race/ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['race/ethnicity'],df['parental level of education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d945b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['race/ethnicity'],df['lunch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['race/ethnicity'],df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['parental level of education'],df['race/ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5886489",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.count_plot_for_variables(df,'parental level of education','test preparation course','dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.count_plot_for_variables(df,'race/ethnicity','test preparation course','bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.count_plot_for_variables(df,'lunch','test preparation course','rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_Marks_with_math_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_Marks_with_writing_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71206ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_Pass_Math_with_math_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_total_Score_with_math_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_percentage_with_total_Score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_pass_reading_with_reading_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd503276",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Calculate_status_with_pass_math_and_pass_writing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8896de",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.pie_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grades'] = df.apply(lambda x: visualizer.getgrade(x['percentage'], x['status']), axis = 1 )\n",
    "    \n",
    "df['grades'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cross_tab_with_stacked_bar_chart(df,df['parental level of education'],df['grades'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.count_plot_for_variables(df,'parental level of education','grades','dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race/ethnicity'] = df['race/ethnicity'].replace('group A', 1)\n",
    "df['race/ethnicity'] = df['race/ethnicity'].replace('group B', 2)\n",
    "df['race/ethnicity'] = df['race/ethnicity'].replace('group C', 3)\n",
    "df['race/ethnicity'] = df['race/ethnicity'].replace('group D', 4)\n",
    "df['race/ethnicity'] = df['race/ethnicity'].replace('group E', 5)\n",
    "\n",
    "df['race/ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grades'] = df['grades'].replace('O', 0)\n",
    "df['grades'] = df['grades'].replace('A', 1)\n",
    "df['grades'] = df['grades'].replace('B', 2)\n",
    "df['grades'] = df['grades'].replace('C', 3)\n",
    "df['grades'] = df['grades'].replace('D', 4)\n",
    "df['grades'] = df['grades'].replace('E', 5)\n",
    "\n",
    "df['race/ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "class Base_Feature_Engineering():\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Feature Engineering object created\")\n",
    "    \n",
    "    def _Label_Encoding(self,data):\n",
    "        category_col =[var for var in data.columns if data[var].dtypes ==\"object\"] \n",
    "        labelEncoder = preprocessing.LabelEncoder()\n",
    "        mapping_dict={}\n",
    "        for col in category_col:\n",
    "            data[col] = labelEncoder.fit_transform(data[col])\n",
    "            le_name_mapping = dict(zip(labelEncoder.classes_, labelEncoder.transform(labelEncoder.classes_)))\n",
    "            mapping_dict[col]=le_name_mapping\n",
    "            return mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c22b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = Base_Feature_Engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe._Label_Encoding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Model_Selector():\n",
    "\n",
    "    def __init__(self,n_estimators=100,random_state=42,max_depth=10):\n",
    "        print(\"Model Selector object created\")\n",
    "        \n",
    "    def Classification_Model_Selector(self,df):\n",
    "        seed = 42\n",
    "        models = []\n",
    "        models.append((\"LR\", LogisticRegression()))\n",
    "        models.append((\"RF\", RandomForestClassifier()))\n",
    "        models.append((\"KNN\", KNeighborsClassifier()))\n",
    "        models.append((\"CART\", DecisionTreeClassifier()))\n",
    "        models.append((\"XGB\", XGBClassifier()))\n",
    "        result = []\n",
    "        names = []\n",
    "        scoring = 'accuracy'\n",
    "        seed = 42\n",
    "\n",
    "        for name, model in models:\n",
    "            x = df.drop(['grades'],axis=1)\n",
    "            y = df['grades']\n",
    "            x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=None)\n",
    "            kfold = KFold(n_splits = 5, random_state =None)# 5 split of data (value of k)\n",
    "            cv_results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = scoring)\n",
    "            result.append(cv_results)\n",
    "            names.append(name)\n",
    "            msg = (name, cv_results.mean(), cv_results.std())\n",
    "            print(msg)\n",
    "        fig = plt.figure(figsize = (8,4))\n",
    "        fig.suptitle('Algorithm Comparison')\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        plt.boxplot(result)\n",
    "        ax.set_xticklabels(names)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "MS = Model_Selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MS.Classification_Model_Selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "x = df.drop(['grades'],axis=1)\n",
    "y = df['grades']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=None)\n",
    "class Data_Modelling():\n",
    "\n",
    "    def __init__(self,n_estimators=100,random_state=None,max_depth=10):\n",
    "        print(\"Data Modelling object created\")\n",
    "\n",
    "    def Decision_Tree_Model(self,df):\n",
    "        Classifier = DecisionTreeClassifier(random_state=None)\n",
    "        clf=Classifier.fit(x_train,y_train)\n",
    "        DT_pred=Classifier.predict(x_test)\n",
    "        print(\"confusion matrix\",confusion_matrix(y_test, DT_pred))\n",
    "        print(\"classification_report\",classification_report(y_test,DT_pred))\n",
    "        return accuracy_score(y_test,DT_pred)\n",
    "    \n",
    "    def Random_Forest_Model(self,df):\n",
    "        Classifier = RandomForestClassifier(n_estimators=100,random_state=None,max_depth=12)\n",
    "        clf=Classifier.fit(x_train,y_train)\n",
    "        RF_pred=Classifier.predict(x_test)\n",
    "        print(\"confusion matrix\",confusion_matrix(y_test, RF_pred))\n",
    "        print(\"classification_report\",classification_report(y_test,RF_pred))\n",
    "        return accuracy_score(y_test,RF_pred)\n",
    "\n",
    "    def Extreme_Gradient_Boosting_Model(self,df):\n",
    "        Classifier = XGBClassifier(n_estimators=100,random_state=None,max_depth=9,learning_rate=0.07)\n",
    "        clf=Classifier.fit(x_train,y_train)\n",
    "        XGB_pred=Classifier.predict(x_test)\n",
    "        print(\"confusion matrix\",confusion_matrix(y_test, XGB_pred))\n",
    "        print(\"classification_report\",classification_report(y_test,XGB_pred))\n",
    "        return accuracy_score(y_test,XGB_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Data_Modelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd255f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Decision_Tree_Model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2558ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Random_Forest_Model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Extreme_Gradient_Boosting_Model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1167a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
